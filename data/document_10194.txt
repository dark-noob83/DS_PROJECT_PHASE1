The cost to calibrate a $250,000 oscilloscope might be $2,500, or just 1% of the purchase price. The relative cost of calibrating lower-cost equipment can, however, be much higher. Calibration cost for, say, a $1200 oscilloscope such as Keysight's X-Series (Figure 1) might be $300. Instruments such as this MSO-X 3104T now have a two-year calibration cycle. As a result of those calibration costs, many large companies have their own calibration labs. These companies tend to have two or more of the following characteristics: 1  Many pieces of instrumentation.
We've developed a process that extends calibration cycles from one year to two years for many test instruments. Keysight and other test-equipment manufacturers use a network of distributors to sell test equipment. These distributors often keep instruments in their warehouses for one to three months. Instruments such as this MSO-X 3104T now have a two-year calibration cycle. As a result of those calibration costs, many large companies have their own calibration labs. These companies tend to have two or more of the following characteristics: 1  Many pieces of instrumentation.
A Guide to Calibration Intervals. A question we are commonly asked is how often particular items should be calibrated. This is not something that we can explicitly advise our customers on – that is to say, we could not tell you directly what we believe your calibration intervals should be. The first thing to check in these situations is whether a specific standard for the equipment you are using states the frequency requirement. On occasion a standard will explicitly state how frequently equipment should be calibrated if it is used for certain things (i.e. for measurement of exhaust emissions).
The calibration should stay stable over the shelf period without impacting the end-user's calibration interval. As a result, we have a requirement that instruments will hold their calibration for up to 6 months of storage prior to the recommended interval. Instruments such as this MSO-X 3104T now have a two-year calibration cycle. As a result of those calibration costs, many large companies have their own calibration labs. These companies tend to have two or more of the following characteristics: 1  Many pieces of instrumentation.
For many activities, it is not enough to control accuracy at the time of testing or calibration. Instead, such control needs to be extended to cover the periods of equipment usage as well. The principle recourse for extending this control has traditionally been periodic testing or calibration at optimal intervals. 
From Agilent’s perspective, a well-defined calibration interval is one that balances the tradeoffs between the cost and inconvenience of the process and the need to keep test instruments performing within their specifications. 4 Part 2: Performing the statistical analyses If the model under review passes the data-sufficiency tests, then the statistical analyses can proceed. The specific methodology depends on three things: the type of instrument, the length of the existing calibration interval and the sample size.
3 Adjusting the calibration interval In response to customers seeking to reduce instrument cost-of-ownership, we have developed a formal “calibration interval extension” process. The process has two major steps: checking for data sufficiency and, if enough data is avail-able, performing detailed statistical analyses. 4 Part 2: Performing the statistical analyses If the model under review passes the data-sufficiency tests, then the statistical analyses can proceed. The specific methodology depends on three things: the type of instrument, the length of the existing calibration interval and the sample size.
A. In general, NIST does not require or recommend any set recalibration interval for measuring instruments, devices, or standards. Specific recalibration intervals depend on a number of factors including: 1  Accuracy requirements set by customers. 2  Requirements set by contract or regulation. 
UNCERTAINTY GROWTH As stated earlier, reliability targets provide objectives for manag-ing measurement bias uncertainty. This uncertainty is not a static quantity. It begins to grow from the time of test or calibration and increases throughout the test or calibration interval. In the context of this paper, the measurement bias of a parameter is the systematic difference between the ac-tual value of the parameter and its stated or declared value. The stated or declared value is commonly referred to as the nominal value.
While it should not form the sole basis of calibration intervals, inevitably it is necessary to consider the cost of regular calibration. This is why it is often necessary to bring in a usage system, or a system that operates various frequencies, as this means you can control costs more effectively. The first thing to check in these situations is whether a specific standard for the equipment you are using states the frequency requirement. On occasion a standard will explicitly state how frequently equipment should be calibrated if it is used for certain things (i.e. for measurement of exhaust emissions).