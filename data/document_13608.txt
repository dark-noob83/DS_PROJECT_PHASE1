The components of a cluster are usually connected to each other through fast local area networks (LAN), with each node (computer used as a server) running its own instance of an operating system. When a node in a cluster fails, strategies such as  fencing  may be employed to keep the rest of the system operational. Fencing is the process of isolating a node or protecting shared resources when a node appears to be malfunctioning.
A majority node set is a single quorum resource, from a server cluster perspective; however, the data is actually stored on multiple disks across the cluster. A cluster running with a majority node set quorum resource, on the other hand, will only start up or continue running if a majority of the nodes configured for the cluster are up and running and can all communicate with each other. The failure semantics of the cluster are different from a vanilla MSCS cluster.
If a node cannot join an existing cluster because it cannot locate another active node, it attempts to form its own cluster by gaining access to the quorum resource. If access is granted, the node uses the recovery logs to update its cluster database and becomes active as a new cluster. An active node can act as host to cluster groups. When the Cluster service is installed, the administrator must choose whether the node should form its own cluster or join an existing cluster.
Time complexity: O(N) where N is the total number of Cluster nodes. Each node in a Redis Cluster has its view of the current cluster configuration, given by the set of known nodes, the state of the connection we have with such nodes, their flags, properties and assigned slots, and so forth. 
Nodes. A server cluster node is a system that has a working installation of Windows Server 2003, Enterprise Edition or Windows Server 2003, Datacenter Edition and the Cluster service. By definition, a node is always a member of a server cluster. For more information on the Cluster service, see Cluster service. Nodes have the following characteristics: 1  Every node is attached to one or more cluster storage devices. 2  Each cluster storage device attaches one or more disks. 1 Every node is attached to one or more cluster storage devices. 2  Each cluster storage device attaches one or more disks. 3  The disks store all of the cluster's configuration and resource data. 4  Each disk can be owned by only one node at any point in time, but ownership can be transferred between nodes.
The cluster service ensures that the cluster configuration data stored on the majority node set is kept consistent across each cluster node. This allows cluster topologies as follows: If the configuration of the cluster changes, that change is replicated across the different disks. A cluster running with a majority node set quorum resource, on the other hand, will only start up or continue running if a majority of the nodes configured for the cluster are up and running and can all communicate with each other. The failure semantics of the cluster are different from a vanilla MSCS cluster.
When a node attempts to join an existing cluster, the cluster validates the node's name and verifies version compatibility. If the validation process succeeds, the cluster allows the node to join. The node updates its copy of the cluster database from the cluster database on the other active nodes. An active node can act as host to cluster groups. When the Cluster service is installed, the administrator must choose whether the node should form its own cluster or join an existing cluster.
A computer cluster consists of a set of loosely or tightly connected computers that work together so that, in many respects, they can be viewed as a single system. Unlike grid computers, computer clusters have each node set to perform the same task, controlled and scheduled by software. When a node in a cluster fails, strategies such as  fencing  may be employed to keep the rest of the system operational. Fencing is the process of isolating a node or protecting shared resources when a node appears to be malfunctioning.