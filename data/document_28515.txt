The term gigabyte is commonly used to mean either 1000 3 bytes or 1024 3 bytes. The latter originated as compromise technical jargon for byte multiples that needed to be expressed by the powers of 2 but lacked a convenient name. 1 1 GiB = 1073741824 bytes (= 1024 3 B = 2 30 B) is the definition used by Microsoft Windows in reference to computer memory (e.g., RAM). 2  This definition is synonymous with the unambiguous IEC standard name gibibyte.
A gigabyte (GB) is a measure of computer data storage capacity that is roughly equivalent to 1 billion bytes. A gigabyte is two to the 30th power or 1,073,741,824 in decimal notation. The term is pronounced with two hard Gs. The prefix giga comes from a Greek word meaning giant. The base-10 definition of gigabyte uses the decimal system to show that 1 GB is equal to one to the 10 th power of bytes, or 1 billion bytes. This is the standard most storage manufacturers and consumers use today. Computers typically use the binary form of measurement, referred to as base-2.
GB. (Gigabyte). An amount of data equal to approximately 1 billion bytes. Data size is also often measured in MB: 1 GB = 1024 MB. See: Byte. See: MB. As an amount of data, GB is often used to refer to how much data (how many songs, videos, apps, etc.) can be stored on a device or storage medium.
The computer terms such as KB, MB, etc. can be slightly confusing for the PC Beginner. So, here's a little elaboration on these units. The PC measures the size of the data in terms of its own units called bytes. The collection of these bytes is known as kilobytes (KB), Megabytes (MB), etc. 
There are two standards for measuring the number of bytes in a gigabyte: base-10 and base-2. The base-10 definition of gigabyte uses the decimal system to show that 1 GB is equal to one to the 10 th power of bytes, or 1 billion bytes. This is the standard most storage manufacturers and consumers use today. Computers typically use the binary form of measurement, referred to as base-2.
Computer storage and memory is often measured in megabytes (MB) and gigabytes (GB). A medium-sized novel contains about 1 MB of information. 1 MB is 1,024 kilobytes, or 1,048,576 (1024x1024) bytes, not one million bytes. 
›› Definition: Megabyte. A megabyte is a unit of information or computer storage equal to 1,048,576 bytes. The official SI definition uses the mebibyte or MiB unit to represent 2 20 bytes. However, most people have requested the more common usage, so the non-SI version is used on this site. The main non-SI unit for computer data storage is the byte. 1 byte is equal to 9.53674316406E-7 MB, or 9.31322574615E-10 GB. Note that rounding errors may occur, so always check the results. Use this page to learn how to convert between megabytes and gigabytes.
The gigabyte (/ˈɡɪɡəbaɪt/ GIG-ə-byt or /ˈdʒɪɡəbaɪt/) is a multiple of the unit byte for digital information. The prefix giga means 10 9 in the International System of Units (SI), therefore one gigabyte is 1000000000bytes. The unit symbol for the gigabyte is GB. This definition is used in all contexts of science, engineering, business, and many areas of computing, including hard drive, solid state drive, and tape capacities, as well as data transmission speeds. 1 1 GiB = 1073741824 bytes (= 1024 3 B = 2 30 B) is the definition used by Microsoft Windows in reference to computer memory (e.g., RAM). 2  This definition is synonymous with the unambiguous IEC standard name gibibyte.
A megabyte is 10 6 or 1,000,000 bytes. One megabyte (abbreviated MB) is equal to 1,000 kilobytes and precedes the gigabyte unit of measurement. While a megabyte is technically 1,000,000 bytes, megabytes are often used synonymously with mebibytes, which contain 1,048,576 bytes (2 20 or 1,024 x 1,024 bytes). Megabytes are often used to measure the size of large files.